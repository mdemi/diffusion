{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from Diffusion import *\n",
    "from utils import makedir\n",
    "import torch\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "from torch.utils.data import DataLoader as DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import h5py as h5\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "local_storage_dir = \"/home/md775/LocalStorage/MLProjects/Diffusion/\" # Change this to your storage directory\n",
    "dataset_path = local_storage_dir + \"Datasets/RegularTriangulations/dataset.h5\"\n",
    "checkpoint_dir = local_storage_dir + \"Checkpoints/Triangulations/\"\n",
    "log_dir = local_storage_dir + \"Logs/\"\n",
    "sample_dir = os.getcwd() + \"/samples/triangulations/\"\n",
    "gif_dir = os.getcwd() + \"/gifs/\"\n",
    "makedir(checkpoint_dir)\n",
    "makedir(log_dir)\n",
    "makedir(sample_dir)\n",
    "makedir(gif_dir)\n",
    "num_channels = 1 # 1 for grayscale\n",
    "num_timesteps = 2000 # Number of timesteps of the diffusion process\n",
    "beta_min = 1e-6\n",
    "beta_max = 0.99\n",
    "image_size = 8\n",
    "batch_size = 2**10\n",
    "max_dataset_size = -1 # Set to -1 to use the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "class hdf5Dataset(Dataset):\n",
    "    def __init__(self, dataset_path, load_all=False, transform=None):\n",
    "        self.transform = transform\n",
    "        self.dataset_path = dataset_path\n",
    "        self.load_all = load_all\n",
    "        if load_all:\n",
    "            self.dataset = h5.File(dataset_path, 'r')['height_images'][:]\n",
    "            self.dataset = self.dataset[:,None,:,:]\n",
    "            self.dataset = torch.from_numpy(self.dataset).float()\n",
    "        else:\n",
    "            self.dataset = h5.File(dataset_path, 'r')['height_images']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.load_all:\n",
    "            image = self.dataset[idx]\n",
    "        else:\n",
    "            image = self.dataset[idx][None,:,:]\n",
    "            image = torch.from_numpy(image).float()\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image        \n",
    "\n",
    "#transform = transforms.Resize((image_size, image_size), antialias=True)\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((image_size, image_size), antialias=True), \n",
    "# ])\n",
    "transform = transforms.Lambda(lambda t: 16*t) # Scale the images to make sure noising is not too weak or too strong\n",
    "\n",
    "image_dataset = hdf5Dataset(dataset_path, load_all=False, transform=transform)\n",
    "dataloader = DataLoader(image_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=16, pin_memory=True, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create diffusion model\n",
    "DiffusionModel = Diffusion(\n",
    "    image_size=image_size,\n",
    "    num_channels = num_channels,\n",
    "    num_timesteps=num_timesteps,\n",
    "    beta_min=beta_min,\n",
    "    beta_max=beta_max,\n",
    "    beta_schedule=\"cosine\",\n",
    "    batch_size=batch_size,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize forward process\n",
    "def image_from_tensor(tensor):\n",
    "    reverse_transforms = transforms.Compose([\n",
    "        transforms.Lambda(lambda t: t.permute(1, 2, 0)), # CHW to HWC\n",
    "        transforms.Lambda(lambda t: t.cpu().numpy().astype(np.float32)),\n",
    "    ])\n",
    "    return reverse_transforms(tensor)\n",
    "\n",
    "initial_tensor = next(iter(dataloader)).to(device)\n",
    "plt.imshow(image_from_tensor(initial_tensor[0]), cmap='gray')\n",
    "\n",
    "plt.figure(figsize=(30,60))\n",
    "num_images = 16\n",
    "stepsize = int(num_timesteps/num_images)\n",
    "for idx in range(0, num_timesteps):\n",
    "    if idx % stepsize == 0:\n",
    "        t = torch.Tensor([idx]).type(torch.int64)\n",
    "        plt.subplot(int(num_images+1/8)+1, 8, int(idx/stepsize) + 1)\n",
    "        tensor, noise = DiffusionModel.forward_process(initial_tensor[0,None], t)\n",
    "        plt.imshow(image_from_tensor(tensor[0]), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Unet model\n",
    "model = DiffusionModel.create_model(\n",
    "    num_init_ch=64,\n",
    "    num_downsamples=2,\n",
    "    num_mid_convs=1\n",
    "    )\n",
    "print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99, last_epoch=-1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def loss_fn(true,pred):\n",
    "    return F.mse_loss(true, pred) + F.l1_loss(true, pred)\n",
    "\n",
    "load_from_checkpoint = False\n",
    "if load_from_checkpoint:\n",
    "    DiffusionModel.load_from_checkpoint(checkpoint_dir+\"model_min_loss.pt\", model, optimizer, lr_scheduler)\n",
    "    \n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "DiffusionModel.train_model(\n",
    "    epochs=200,\n",
    "    data_loader=dataloader,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    loss_function=loss_fn,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    checkpoint_interval=1,\n",
    "    log_dir=log_dir+timestamp\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from model\n",
    "DiffusionModel.load_from_checkpoint(checkpoint_dir+\"model_min_loss.pt\", model)\n",
    "tensor_sample = DiffusionModel.sample(num_images=1, variance_coeff=1.0)\n",
    "tensor_sample = tensor_sample.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sample\n",
    "makedir(sample_dir)\n",
    "with open(sample_dir + \"height_images.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tensor_sample.numpy()[0], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create triangulations\n",
    "# This requires CYTools. See https://cy.tools/ for installation instructions and more information.\n",
    "! docker run --rm -it --name cytools-uid-$UID -v ./:/home/cytools/mounted_volume -p $(($UID+2875)):$(($UID+2875)) cytools:uid-$UID python3 ./cytools_triangulate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE REVERSE PROCESS\n",
    "plt.figure(figsize=(60,60))\n",
    "num_step_images = 10\n",
    "stepsize = int(num_timesteps/num_step_images)\n",
    "\n",
    "tensors = tensor_sample[0]\n",
    "for i, tensor in enumerate(tensors):\n",
    "    if i % stepsize == 0:\n",
    "        plt.subplot(int(num_step_images+1/8)+1, 8, int(i/stepsize) + 1)\n",
    "        plt.imshow(image_from_tensor(tensor), cmap=\"gray\")\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image_from_tensor(tensors[-1]), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize triangulations\n",
    "\n",
    "# Load triangulations\n",
    "points_list = np.load(sample_dir + \"points.pkl\", allow_pickle=True)\n",
    "simplices_list = np.load(sample_dir + \"simplices.pkl\", allow_pickle=True)\n",
    "\n",
    "def Plot_2D_Triangulation(points, simplices):\n",
    "    edges = np.unique(np.concatenate([((ss[0],ss[1]),(ss[0],ss[2]),(ss[1],ss[2])) for ss in simplices]),axis=0)\n",
    "    x = points[:,0].flatten()\n",
    "    y = points[:,1].flatten()\n",
    "    return plt.plot(x[edges.T], y[edges.T], linestyle='-', color='b', markerfacecolor='red', marker='.')  \n",
    "    \n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "num_images = 10\n",
    "num_timesteps = len(points_list)\n",
    "stepsize = int(num_timesteps/num_images)\n",
    "\n",
    "for idx in range(0, num_timesteps, stepsize):\n",
    "    plt.subplot(int(num_images+1/8)+1, 8, int(idx/stepsize) + 1)\n",
    "    Plot_2D_Triangulation(points_list[idx], simplices_list[idx])\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "Plot_2D_Triangulation(points_list[-1], simplices_list[-1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantify fine-ness\n",
    "point_counts = []\n",
    "for s in tqdm(simplices_list):\n",
    "    unique_points = np.unique(s.flatten())\n",
    "    point_counts.append(len(unique_points))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(point_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gif\n",
    "from PIL import Image\n",
    "images = []\n",
    "num_images = 200\n",
    "stepsize = int(num_timesteps/num_images)\n",
    "for t in range(0, num_timesteps):\n",
    "    if t % stepsize == 0:\n",
    "        plt_figure = plt.figure(figsize=(5,5))\n",
    "        Plot_2D_Triangulation(points_list[t], simplices_list[t])\n",
    "        plt_figure.canvas.draw()\n",
    "        image = Image.frombytes('RGB',plt_figure.canvas.get_width_height(),plt_figure.canvas.tostring_rgb())\n",
    "        images.append(image)\n",
    "        plt.close()\n",
    "images[0].save(gif_dir + '/triangulations.gif', save_all=True, append_images=images[1:], duration=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
